{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from requests.auth import HTTPBasicAuth\n",
    "# from GrafanaPrometheusDataFetcher import GrafanaPrometheusDataFetcher\n",
    "\n",
    "class GrafanaDashboardProcessor:\n",
    "    def __init__(self, grafana_url, api_key, dashboard_uid, username, password, start_time_str, end_time_str):\n",
    "        self.grafana_url = grafana_url\n",
    "        self.api_key = api_key\n",
    "        self.dashboard_uid = dashboard_uid\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        \n",
    "        # Convert human-readable dates to Unix timestamps\n",
    "        self.start_time = self.convert_to_unix(start_time_str)\n",
    "        self.end_time = self.convert_to_unix(end_time_str)\n",
    "        \n",
    "        # Store the processed data\n",
    "        self.data = {}\n",
    "\n",
    "    def convert_to_unix(self, time_str):\n",
    "        return int(time.mktime(datetime.strptime(time_str, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "\n",
    "    def fetch_dashboard(self):\n",
    "        dashboard_url = f\"{self.grafana_url}/api/dashboards/uid/{self.dashboard_uid}\"\n",
    "        response = requests.get(dashboard_url, auth=HTTPBasicAuth(self.username, self.password))\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            response.raise_for_status()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_metric_name(expr):\n",
    "        if \"{\" in expr:\n",
    "            return expr.split(\"{\")[0].strip()\n",
    "        return expr.strip()\n",
    "\n",
    "    def process_panels(self, dashboard_data):\n",
    "        for panel in dashboard_data['dashboard']['panels']:\n",
    "            panel_id = panel['id']\n",
    "            panel_title = panel.get('title', 'Unnamed Panel')\n",
    "            panel_type = panel.get('type', 'Unknown')\n",
    "\n",
    "            for target in panel.get('targets', []):\n",
    "                prom_query = target.get('expr', None)\n",
    "                datasource_data = target.get('datasource', None)\n",
    "\n",
    "                if prom_query and datasource_data:\n",
    "                    uid = datasource_data['uid']\n",
    "                    type_name = datasource_data['type']\n",
    "                    metric_name = self.extract_metric_name(prom_query)\n",
    "\n",
    "                    # Initialize the uid structure if it doesn't exist\n",
    "                    if uid not in self.data:\n",
    "                        self.data[uid] = {\n",
    "                            \"uid_details\": {\n",
    "                                \"type_name\": type_name,\n",
    "                                \"uid\": uid\n",
    "                            },\n",
    "                            uid: {}\n",
    "                        }\n",
    "\n",
    "                    # Initialize the panel_type structure under the uid if it doesn't exist\n",
    "                    if panel_type not in self.data[uid][uid]:\n",
    "                        self.data[uid][uid][panel_type] = {\n",
    "                            \"expr_list\": [],\n",
    "                            \"panels\": []\n",
    "                        }\n",
    "\n",
    "                    # Append the metric name to expr_list\n",
    "                    self.data[uid][uid][panel_type][\"expr_list\"].append(metric_name)\n",
    "\n",
    "                    # Construct panel_info\n",
    "                    panel_info = {\n",
    "                        \"id\": panel_id,\n",
    "                        \"title\": panel_title,\n",
    "                        \"datasource\": datasource_data\n",
    "                    }\n",
    "\n",
    "                    # Append the panel_info under the appropriate panel_type\n",
    "                    self.data[uid][uid][panel_type][\"panels\"].append(panel_info)\n",
    "        return self.data\n",
    "\n",
    "    @staticmethod\n",
    "    def save_to_file(file_name, data):\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "    def run(self):\n",
    "        dashboard_data = self.fetch_dashboard()\n",
    "        self.process_panels(dashboard_data)\n",
    "        self.save_to_file('datasource.json',self.data)\n",
    "        print(json.dumps(self.data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "class GrafanaPrometheusDataFetcher:\n",
    "    def __init__(self, url, username, password, query_url):\n",
    "        self.url = url\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.query_url = query_url\n",
    "        \n",
    "    def fetch_data(self, body):\n",
    "        \"\"\"Fetches data from the Prometheus API.\"\"\"\n",
    "        try:\n",
    "            response = requests.post(self.query_url, auth=HTTPBasicAuth(self.username, self.password), json=body)\n",
    "            response.raise_for_status()\n",
    "            print(\"Data retrieved successfully\")\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to retrieve data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def process_data(self, data, ref_id='A'):\n",
    "        \"\"\"Processes the JSON data and converts it into a Pandas DataFrame.\"\"\"\n",
    "        metrics = []\n",
    "        for frame in data['results'][ref_id]['frames']:\n",
    "            labels = frame['schema']['fields'][1]['labels']\n",
    "            times = frame['data']['values'][0]\n",
    "            values = frame['data']['values'][1]\n",
    "            for t, v in zip(times, values):\n",
    "                metrics.append({'Time': t, 'Value': v, **labels})\n",
    "        df = pd.DataFrame(metrics)\n",
    "        df['Time'] = pd.to_datetime(df['Time'], unit='ms')\n",
    "        return df\n",
    "    \n",
    "    def plot_data(self, df, expr):\n",
    "        \"\"\"Plots the data from the DataFrame.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Time'], df['Value'], label=f'{expr} Rate', color='blue')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Time Series of {expr} Rate')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    def build_query_body(self, expr, from_time, to_time, queries_type, uid):\n",
    "        \"\"\"Builds the query body for fetching data.\"\"\"\n",
    "        return {\n",
    "            \"queries\": [\n",
    "                {\n",
    "                    \"refId\": \"A\",\n",
    "                    \"expr\": f\"rate({expr}[$__rate_interval])\",\n",
    "                    \"range\": True,\n",
    "                    \"datasource\": {\"type\": queries_type, \"uid\": uid},\n",
    "                    \"intervalMs\": 15000,\n",
    "                    \"maxDataPoints\": 1539\n",
    "                },\n",
    "                {\n",
    "                    \"refId\": \"A-Instant\",\n",
    "                    \"expr\": f\"rate({expr}[$__rate_interval])\",\n",
    "                    \"instant\": True,\n",
    "                    \"datasource\": {\"type\": queries_type, \"uid\": uid},\n",
    "                    \"intervalMs\": 15000,\n",
    "                    \"maxDataPoints\": 1539\n",
    "                }\n",
    "            ],\n",
    "            \"from\": from_time,\n",
    "            \"to\": to_time\n",
    "        }\n",
    "    \n",
    "    def get_resources(self, path):\n",
    "        \"\"\"Fetches available resources from the Prometheus API.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.url}{path}\", auth=HTTPBasicAuth(self.username, self.password))\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('data', [])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to retrieve resources: {e}\")\n",
    "            return []\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_to_timestamp(date_str):\n",
    "        \"\"\"Converts a date string to a Unix timestamp in milliseconds.\"\"\"\n",
    "        dt = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "        return str(int(dt.timestamp() * 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric Names: ['calls_total', 'duration_milliseconds_bucket', 'duration_milliseconds_count', 'duration_milliseconds_sum', 'scrape_duration_seconds', 'scrape_samples_post_metric_relabeling', 'scrape_samples_scraped', 'scrape_series_added', 'target_info', 'up']\n",
      "Data retrieved successfully\n",
      "Data for calls_total:\n",
      "Data retrieved successfully\n",
      "Data for duration_milliseconds_bucket:\n",
      "Data retrieved successfully\n",
      "Data for duration_milliseconds_count:\n",
      "Data retrieved successfully\n",
      "Data for duration_milliseconds_sum:\n",
      "Data retrieved successfully\n",
      "Data for scrape_duration_seconds:\n",
      "Data retrieved successfully\n",
      "Data for scrape_samples_post_metric_relabeling:\n",
      "Data retrieved successfully\n",
      "Data for scrape_samples_scraped:\n",
      "Data retrieved successfully\n",
      "Data for scrape_series_added:\n",
      "Data retrieved successfully\n",
      "Data for target_info:\n",
      "Data retrieved successfully\n",
      "Data for up:\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "# from GrafanaPrometheusDataFetcher import GrafanaPrometheusDataFetcher\n",
    "# from GrafanaDashboardProcessor import GrafanaDashboardProcessor\n",
    "\n",
    "def main():\n",
    "    # Define necessary parameters\n",
    "    GRAFANA_URL = \"https://op.cloudbuilders.io\"\n",
    "    API_KEY = \"glsa_Y8WYTAWLM3BoHHDGYSUb86e59kbGkBIw_523e9ead\"\n",
    "    DASHBOARD_UID = \"opentelemetry-apm\"\n",
    "    \n",
    "    username = 'admin'\n",
    "    password = 'Imfine123$'\n",
    "    timeframes = ['2024-08-22 13:06:55', '2024-08-22 14:06:55']\n",
    "    \n",
    "    # Create an instance of the processor\n",
    "    processor = GrafanaDashboardProcessor(\n",
    "        grafana_url=GRAFANA_URL,\n",
    "        api_key=API_KEY,\n",
    "        dashboard_uid=DASHBOARD_UID,\n",
    "        username=username,\n",
    "        password=password,\n",
    "        start_time_str=timeframes[0],\n",
    "        end_time_str=timeframes[1]\n",
    "    )\n",
    "    \n",
    "    # Fetch and process the dashboard data\n",
    "    dashboard_data = processor.fetch_dashboard()\n",
    "    data = processor.process_panels(dashboard_data)\n",
    "    \n",
    "    # Example usage of GrafanaPrometheusDataFetcher for fetching Prometheus data\n",
    "    for uid in data:\n",
    "        type_name = data[uid]['uid_details']['type_name']\n",
    "        query_url = f\"{GRAFANA_URL}/api/ds/query?ds_type={type_name}&requestId=explore_x25\"\n",
    "        fetcher = GrafanaPrometheusDataFetcher(GRAFANA_URL, username, password, query_url)\n",
    "        \n",
    "        from_time = fetcher.convert_to_timestamp(timeframes[0])\n",
    "        to_time = fetcher.convert_to_timestamp(timeframes[1])\n",
    "        \n",
    "        # Path to get resource names (e.g., Prometheus metric names)\n",
    "        path = f\"/api/datasources/uid/{uid}/resources/api/v1/label/__name__/values?start=1724389980&end=1724393640\"\n",
    "        expr_list = fetcher.get_resources(path=path)\n",
    "        \n",
    "        print(\"Metric Names:\", expr_list)\n",
    "        \n",
    "        # Initialize main_df as a dictionary to hold DataFrames for each expr\n",
    "        main_df = {}\n",
    "        output_dir_csv = 'output_csv'\n",
    "        output_dir_json = 'output_json'\n",
    "        \n",
    "        # Ensure the output directory exists\n",
    "        if not os.path.exists(output_dir_csv):\n",
    "            os.makedirs(output_dir_csv)\n",
    "\n",
    "         # Ensure the output directory exists\n",
    "        if not os.path.exists(output_dir_json):\n",
    "            os.makedirs(output_dir_json)\n",
    "        \n",
    "        # Loop through each metric and process data\n",
    "        for expr in expr_list:\n",
    "            body = fetcher.build_query_body(expr, from_time, to_time, type_name, uid)\n",
    "            json_data = fetcher.fetch_data(body)\n",
    "            \n",
    "            if json_data:\n",
    "                # Save the data to a file\n",
    "                processor.save_to_file(f'{output_dir_json}/{expr}.json',json_data)\n",
    "                \n",
    "                \n",
    "                # Process the data into a DataFrame\n",
    "                df = fetcher.process_data(json_data)\n",
    "                \n",
    "                # Save the DataFrame to a CSV file for easier inspection\n",
    "                df.to_csv(f'{output_dir_csv}/{expr}.csv', index=False)\n",
    "\n",
    "                # Plot the data\n",
    "                # fetcher.plot_data(df, expr)\n",
    "                \n",
    "                # Initialize the key in main_df if it doesn't exist\n",
    "                if expr not in main_df:\n",
    "                    main_df[expr] = []\n",
    "                \n",
    "                # Append the DataFrame to the list for that metric\n",
    "                main_df[expr].append(df)\n",
    "                \n",
    "                # Print the DataFrame (table format)\n",
    "                print(f\"Data for {expr}:\")\n",
    "                # print(df.to_string())  # This prints the entire DataFrame as a table\n",
    "                # print(df.head())\n",
    "        \n",
    "        # Print the final main_df dictionary\n",
    "        # print(\"\"\"(((((((main_df)))))))\"\"\")\n",
    "        # test=main_df['calls_total']\n",
    "        # print(test)\n",
    "        print(\"END\")\n",
    "        \n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
